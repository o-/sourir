# The formal language

x        variables

P ::= Function main   ↦ F, (Df ↦ F)*   program:            main function and other functions
F ::= Segment  active ↦ S, (Ds ↦ S)*   function:           active version and others
S ::= start ↦ i,           I           segment:            instruction stream with dedicated start
I ::= (l ↦ i)*                         instruction stream: labeled instructions

Df ::= Function f[x, ...](y, ...)  function declaration
Ds ::= Segment  s                  segment declaration

f  function name
s  optimization version
l  labels

main      main function
active    active segment
start     start label

a  addresses


i ::=    instructions
| const x = e                   constant variable
| mut x = e                     mutable variable
| x <- e                        assignment
| branch x l₁ l₂                conditional
| goto l                        goto
| print x                       print
| return x                      return
| const a = call x_f (x, ...)   call
| osr(e, s, l, (x = ee)*)       osr : (can be used for osr-in and osr-out)

ee ::=   extended expression
| e
| ⊥

e ::=    (simple) expressions
| lit                   literals
| x                     variables
| primop(x, ...)        primitive operation (pure)
| close f[x, ...]       create closure

lit ::=  litterals
| nil
| true | false
| 0 | 1 | 2 | ...

v :=     values
| lit                   literals

(Note: heap adresses are not values)

# Natural operational semantics

succ I l =
 | goto l'                                -> [l']
 | branch _ l' l''                        -> [l', l'']
 | when I = {..., l -> _, l' -> _, ...}   -> [l']
 | _                                      -> []

pred I l =
  { l' ∈ I : succ I l' = l }

E ::= (x ↦ const v | x ↦ var a | x ↦ ⊥)*  lexical environment
H ::= (l ↦ v)                             mutable heap

T ::= (lit)*                    output trace

Configuration: (T, H, E, P, I, l)

Lookup (partial) function, returns a v:
  (H,E)[x] :=
    v    if E ∋ (x ↦ const v)
    H(l) if E ∋ (x ↦ mut l)

Update (partial) function, returns a S:
  (H,E)[x ← v] :=
    H[E(x) ↦ v] if E ∋ (x ↦ mut l)

Evaluation of simple expressions:

  eval H E P x = (H,E)[x]
  eval H E P lit = lit
  eval H E P primop(x₁, ..., xₙ) = 〚primop〛((H,E)[x₁], ..., (H,E)[xₙ])
  eval H E P close f[y, ...] = (f, E[(x ↦ y)*])
    when dom(P) ∋ Function [x, ...](...)

Evaluation of extended expressions

  eeval H E P ⊥ = ⊥
  eeval H E P e = eval H E P e

Machine state (P, T, H, E*, C*) :
  program, trace, heap, environments, continuations

Reduction relation
  (P, T, H, E*, C* (f, s, l)) -> (P, (T, (H,E)[x]), H, E*, C* (f, s, l'))
    when P(f,s,l) = print x
     and l'      := succ P(f,s) l

  (P, T, H, E*, C* (f, s, l)) -> (P, T, H, E*, C* (f, s, l'))
    when P(f,s,l) = branch x l₁ l₂
     and l'      := if (H,E)[x] then l₁ else l₂

  (P, T, H, E* E, C* (f, s, l)) -> (P, T, H, E* (E, x ↦ v), C* (f, s, l))
    when P(f,s,l) = const x = e
     and v       := eval H E P x
     and l'      := succ P(f,s) l

  (P, T, H, E* E, C* (f, s, l)) -> (P, T, (H, a ↦ v), E* (E, x ↦ a), (f, s, l'))
    when P(f,s,l) = mut x = e
     and v       := eval H E P e
     and a fresh
     and l'      := succ P(f,s) l

  (P, T, H, E* E, C* (f, s, l)) -> (P, T, (H,E)[x] := v, E* E, (f, s, l'))
    when P(f,s,l) = x ← e
     and v       := eval H E P x
     and l'      := succ P(f,s) l

  (P, T, H, E*, C* (f, s, l)) -> (P, T, H, E* E'', C* (f, s, l) (f', active, start))
    when P(f,s,l) = const a = call x_f (x, ...)
     and (f', E') = (H,E)[x_f]
     and E''     := E'[(x ↦ (H,E)[x])*]


  (P, T, H, E* E' E, C* (f', s', l') (f, s, l)) -> (P, T, H, E* E'', C* (f', s', l''))
    when P(f,s,l)    = return x
     and P(f',s',l') = const a = call _
     and v          := (H,E)[x]
     and E''        := E'[a ↦ v]
     and l''        := succ P(f',s') l'

  (P, T, H, E* E, C* (f, s, l)) -> (P, T, H, E* E, C* (f, s, l'))
    when P(f,s,l) = osr(e, _, _)
     and (eval H E P e) is not (true)
     and l'      := succ P(f,s) l

  (P, T, H, E* E, C* (f, s, l)) -> (P, T, H, E* E', C* (f, s', l'))
    when P(f,s,l) = osr(e, s', l', (x = ee)*)
     and (eval H E P e) is (true)
     and E'  := (x ↦ (eeval H E ee))*


# Scopes

declares i =
  | mut x _         -> [x]
  | const x _       -> [x]
  | _               -> []

requires i =
  | mut x = e
  | const x = e
  | osr (e, v, l, (x = ee)*)
                    -> vars(e) ∪ vars(ee)*
  | x <- e          -> x :: vars(e)
  | branch x _
  | print x         -> [x]
  | _               -> []

scope S ::= x*
scope assignment A ::= ((v, l) → S)*

## Declarative scoping judgment

This judgment just classifies "possible" scope assignments A for
a program P. It does not characterize the tightest possible
assignment¹, as it allows to implicitly drop variables from scope on
each transition (the ⊇ relations in the (v, l → i) rule). In
particular, it cannot forbid shadowing, as it is always possible to
drop all same-named bindings before a declaration.

¹: the tightest possible assignment can be defined impredicatively as
the pointwise intersection of all valid judgments, which is
well-defined given that valid scopes are bounded by the set of
variables defined in the program.

  ∀(v → M) ∈ P:   A, P ⊨d v → M
  ----------------------------
            A, P ⊨d

  ∀(l → i) ∈ M:   A, P ⊨d v, l → i
  -------------------------------
         A, P ⊨d v → M

  requires i ⊆ A(v,l)
  ∀l' ∈ succ(P(v),l),  A(v,l) ∪ declares i ⊇ A(v,l')
  A, P ⊨d i : A(v,l)
  pred(P(v), l) = ∅  ⇒  i = start
  -----------------------------------------------------------
  A, P ⊨d v, l → i

The judgment (A, P ⊨d i : S) below is the instruction-specific judgment
that checks the scope restrictions that are specific to each
instruction, rather than the general control-flow constraints and the
generic requires/declares handling.

  -----------------
  A, P ⊨d start : ∅

              A(v', l') = x*
  -------------------------------------
  A, P ⊨d osr(e, v', l', (x = ee*)) : S

  ---------------
  A, P ⊨d stop : ∅

  i ∉ {start, osr, stop}
  ----------------------
  A, P ⊨d i : S

## Algorithmic scoping judgment

(A, P ⊨a), (A, P ⊨a v → M), (A, P ⊨a i : S): as in the declarative
scoping judgment. Only (A, P ⊨a v, l → i) differs.

  S := A(v,l) \ declares i
  (⋂_{l* ∈ pred(P(v),l)} A(v,l*)) = S ∪ requires i
  A, P ⊨a i : S
  ------------------------------------------------
  A, P ⊨a v, l → i

There is a fundamental difference in the role of the scope assignment
A between the declarative and algorithmic judgments.

In the declarative judgment, A(v,l) points to the variables
*available* in the *ingoing* scope of the instruction at location
(v,l): the scope that is available when arriving to the instruction
from a predecessor. The variables that are available in the outgoing
scope can be computed from this value as (A(v,l) ∪ declares i).

In the algorithmic judgment, A(v,l) points to the variables that are
*required* in the *outgoing* scope of the instruction at location
(v,l): the scope that is required when leaving the instruction to
a successor. The variables required in the ingoing scope can be
computed from this value as (A(v,l) \ declares i).

In the declarative judgment, the relation between an instruction scope
and its neighbors is under-specified: a predecessor's outgoing scope
may have more variables than our ingoing scope, and any successor's
ingoing scope may have less variable than our outgoing scope.

In the algorithmic judgment, the relation between the scopes of an
instruction and its neighbors is deterministic: an instruction's
ingoing scope is exactly the variables that are common among all its
predecessors. Implicitly dropping a variable that will never be used
again is possible: this is done by choosing a A(v,l) that is smaller
than the instruction's ingoing set plus (declares i).

Problem: I think there is a problem with the notion of outgoing scope
as it is currently defined for multi-successor instructions, as it
forces all successors to see the same set of required
variables. I think that introducing `drop` instructions would be the
cleanest way to work around these issues – by removing any
underspecification from the declarative specification.
